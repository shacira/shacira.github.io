<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>SHACIRA</title>
	<link rel="icon" type="image/x-icon" href="./resources/shacira.png">
	<meta property="og:image" content="resources/Teaser_v2.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations" />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations</span>
		<br>
		<span style="font-size:30px">ICCV 2023</span>
		<br><br>
		<table align=center width=750px>
			<table align=center width=750px>
				<tr>
					<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href="https://sharath-girish.github.io/">Sharath Girish</a></span>
						</center>
					</td>
					<td align=center width=210px>
						<center>
							<span style="font-size:24px"><a href="https://www.cs.umd.edu/~abhinav/">Abhinav Shrivastava</a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href="https://kampta.github.io/">Kamal Gupta</a></span>
						</center>
					</td>
				</tr>
			</table>
			<span style="font-size:20px">University of Maryland, College Park</span>
			<br><br>
			<table align=center width=580px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://www.dropbox.com/e/scl/fi/dttm7p6h4mt518h4c15x1/HashCompression_ICCV2023.pdf?dl=0&rlkey=0ui9bkamhyn04pg7sdixzqyda'>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=120px>
					<center>
						<span style="font-size:24px"><a href='http://shacira.github.io'>[Code (Coming soon)]</a></span>
					</center>
					</td>
					<!-- <td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://arxiv.org/abs/2204.02965'>[arXiv]</a></span><br>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://github.com/Sharath-girish/LilNetX'>[GitHub]</a></span><br>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://youtu.be/RD9aTiqGchM'>[Video]</a></span><br>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://www.dropbox.com/scl/fi/bfta9fmm2jfaggzebiur3/LilNetX.pptx?dl=0&rlkey=jwnb0fopnov25chff17ejfo84'>[Slides]</a></span><br>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://www.dropbox.com/s/foasj8g7bcktjn4/LilNetX%20Poster.pdf?dl=0'>[Poster]</a></span><br>
						</center>
					</td> -->
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=750px>
			<tr>
				<td width=750px>
					<center>
						<img class="round" style="width:750px" src="./resources/Lego-teaser-two-col.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
					We introduce an <b>end-to-end compression framework for feature-grid INRs</b> achieving data compression for
					various domains such as images, videos, NeRFs. We demonstrate the effectiveness of SHACIRA for two tasks. 
					The top row shows a gigapixel image at $21450 \times 56718$ resolution (cropped for visualization) encoded 
					using <a href="https://nvlabs.github.io/instant-ngp/">Instant-NGP</a>, JPEG, 
					and ours (SHACIRA). The bottom row reconstructs NeRF from 2D images and their camera poses using 
					Instant-NGP, <a href="https://nv-tlabs.github.io/vqad/">VQAD</a>, and ours. For each example, 
					we zoom into two crops to compare different methods. We show overall PSNR and size required by each method. 
					Our method can capture <b>high-resolution details with a smaller storage size in a task-agnostic way</b>
					(only 2D/3D examples shown here).

				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Implicit Neural Representations (INR) or neural fields have emerged as a popular framework 
				to encode multimedia signals such as images and radiance fields while retaining high-quality.
 				Recently, learnable feature grids (Instant-NGP) have allowed significant speed-up in the training 
				as well as the sampling of INRs by replacing a large neural network with a multi-resolution look-up 
				table of feature vectors and a much smaller neural network. However, these feature grids come at the 
				expense of large memory consumption which can be a bottleneck for storage and streaming applications.
  				In this work, we propose SHACIRA, a simple yet effective task-agnostic framework for compressing such 
				feature grids with no additional post-hoc pruning/quantization stages. We reparameterize feature grids 
				with quantized latent weights and apply entropy regularization in the latent space to achieve high levels 
				of compression across various domains. Quantitative and qualitative results on diverse datasets 
				consisting of images, videos, and radiance fields, show that our approach outperforms existing 
				INR approaches without the need for any large datasets or domain-specific heuristics.
			</td>
		</tr>
	</table>

	<hr>
	<table align=center width=850px>
		<center><h1>Approach</h1></center>

		<tr>
			<td width=850px>
				<center>
					<img class="round" style="width:800px" src="./resources/approach_v2.png"/>
				</center>
			</td>
		</tr>
		<tr>
			<td>
				Our approach maintains <b>quantized latent representations of the feature grid</b> which 
				consists of a hierarchy representing coarse-to-fine resolutions of the signal. 
				The hierarchical latents are passed through a decoder to obtain continuous feature vectors. 
				The feature vectors at different levels are then concatenated and passed through an MLP
				to obtain the output signal which can be images, videos, NeRFs, and so on.
			</td>
		</tr>
		
	</table>

	<table align=center width=850px>
		<center><h1>Results</h1></center>

		<tr>
			<td width=850px>
				<center>
					<img class="round" style="width:850px" src="./resources/cosmic.png"/>
				</center>
			</td>
		</tr>
		<tr>
			<td>
				We scale well to higher resolution images obtaining similar PSNR and reconstruction quality as 
				Instant-NGP while 6 times smaller. <a href="https://www.vincentsitzmann.com/siren/">SIREN</a>  
				fails to fit high frequency information leading to blurry patches as seen. 
				JPEG on the other hand suffers from blocking artifacts and discoloration leading to drop in reconstruction 
				quality.
			</td>
		</tr>
		<tr>
			<td width=850px>
				<center>
					<img class="round" style="width:800px" src="./resources/V8.png"/>
				</center>
			</td>
		</tr>
		<tr>
			<td>
				We obtain better reconstructions for NeRF scenes preserving much finer detail than VQAD while being visually
				similar to Instant=NGP and being 60x smaller.
			</td>
		</tr>
		
	</table>
	<br>
	<hr>

	<table align=center width=850px>
		<center><h1>Progressive inference-time streaming</h1></center>

		<tr>
			<td width=850px>
				<center>
					<img class="round" style="width:800px" src="./resources/streaming_lod_5.png"/>
				</center>
			</td>
		</tr>
		<tr>
			<td>
				The hierarchical nature of feature-grid based INRs allows for progressive streaming of the scene. 
				Even for our latent-based approach, transmitting only coarse resolution latents at inference time
				leads to a coarse scene requiring fewer bits to transmit. Finer details can be captured with the 
				finer resolution latents. This can be useful in streaming scenarios with varying level of detail.
			</td>
		</tr>
		
	</table>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>
